{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdjhCYP0CVzw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"/content/Romeo and Juliet.txt\", \"r\", encoding = \"utf8\")\n",
        "\n",
        "lines = []\n",
        "for i in file:\n",
        "    lines.append(i)"
      ],
      "metadata": {
        "id": "KACZkRdrCnkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ' '. join(lines)"
      ],
      "metadata": {
        "id": "T3EG5Y--EIcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "hz6vWRqPELok",
        "outputId": "396659d9-5e38-44a3-f977-5b07aa0d3aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeff The Project Gutenberg eBook of Romeo and Juliet This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "sDipF0TmC0I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the tokenizer for predict function\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "YlyHdf3GEPn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIcP60yQES9v",
        "outputId": "ed676e92-834e-42a7-9e5d-3b3721eafa8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequence_data)"
      ],
      "metadata": {
        "id": "broOZZfyafrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "o-7hQ1G-aiJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "for i in range(3, len(sequence_data)):\n",
        "    words = sequence_data[i-3:i+1]\n",
        "    sequences.append(words)\n",
        "\n",
        "print(\"The Length of sequences are: \", len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOAKcxaoEVi6",
        "outputId": "49223d8d-984e-4f69-da83-0092ab83c7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Length of sequences are:  29283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "metadata": {
        "id": "su6eSSMteC_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8a7d21-38a2-400e-b9ce-08d6b603a0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1927,    1,   54,  129],\n",
              "       [   1,   54,  129,  306],\n",
              "       [  54,  129,  306,    6],\n",
              "       [ 129,  306,    6,   12],\n",
              "       [ 306,    6,   12,    2],\n",
              "       [   6,   12,    2,   22],\n",
              "       [  12,    2,   22,   16],\n",
              "       [   2,   22,   16,  306],\n",
              "       [  22,   16,  306,    8],\n",
              "       [  16,  306,    8,   18]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in sequences:\n",
        "    X.append(i[0:3])\n",
        "    y.append(i[3])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(\"Data: \", X[:10])\n",
        "print(\"Response: \", y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwJ8-FjNEaCw",
        "outputId": "ad8eeef9-e43d-44e7-d4c9-8812436cdc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[1927    1   54]\n",
            " [   1   54  129]\n",
            " [  54  129  306]\n",
            " [ 129  306    6]\n",
            " [ 306    6   12]\n",
            " [   6   12    2]\n",
            " [  12    2   22]\n",
            " [   2   22   16]\n",
            " [  22   16  306]\n",
            " [  16  306    8]]\n",
            "Response:  [129 306   6  12   2  22  16 306   8  18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COS0SOo1Edk8",
        "outputId": "ba1b380a-b749-4d82-aeb0-f4ed6f794131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "zzV83aQaC1Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h9yCyQeC42H",
        "outputId": "879651e0-211b-4b40-c0df-680441a4d4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 3, 10)             42970     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4297)              4301297   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17393267 (66.35 MB)\n",
            "Trainable params: 17393267 (66.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='plot.png', show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "OqxgekZkC5lL",
        "outputId": "8ff845a4-0078-4099-e837-f0ef266ee51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(X, y, epochs=50, batch_size=64, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFjIT4yIC8Zj",
        "outputId": "89b90492-6a93-4d87-ef15-d1c64d336a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 6.8146\n",
            "Epoch 1: loss improved from inf to 6.81460, saving model to next_words.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r458/458 [==============================] - 311s 667ms/step - loss: 6.8146\n",
            "Epoch 2/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 6.4303\n",
            "Epoch 2: loss improved from 6.81460 to 6.43030, saving model to next_words.h5\n",
            "458/458 [==============================] - 300s 656ms/step - loss: 6.4303\n",
            "Epoch 3/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 6.1660\n",
            "Epoch 3: loss improved from 6.43030 to 6.16599, saving model to next_words.h5\n",
            "458/458 [==============================] - 303s 660ms/step - loss: 6.1660\n",
            "Epoch 4/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 5.9084\n",
            "Epoch 4: loss improved from 6.16599 to 5.90844, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 645ms/step - loss: 5.9084\n",
            "Epoch 5/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 5.6298\n",
            "Epoch 5: loss improved from 5.90844 to 5.62976, saving model to next_words.h5\n",
            "458/458 [==============================] - 294s 642ms/step - loss: 5.6298\n",
            "Epoch 6/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 5.3603\n",
            "Epoch 6: loss improved from 5.62976 to 5.36029, saving model to next_words.h5\n",
            "458/458 [==============================] - 294s 643ms/step - loss: 5.3603\n",
            "Epoch 7/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 5.1073\n",
            "Epoch 7: loss improved from 5.36029 to 5.10732, saving model to next_words.h5\n",
            "458/458 [==============================] - 292s 638ms/step - loss: 5.1073\n",
            "Epoch 8/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 4.8569\n",
            "Epoch 8: loss improved from 5.10732 to 4.85693, saving model to next_words.h5\n",
            "458/458 [==============================] - 293s 641ms/step - loss: 4.8569\n",
            "Epoch 9/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 4.5880\n",
            "Epoch 9: loss improved from 4.85693 to 4.58796, saving model to next_words.h5\n",
            "458/458 [==============================] - 289s 632ms/step - loss: 4.5880\n",
            "Epoch 10/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 4.2990\n",
            "Epoch 10: loss improved from 4.58796 to 4.29899, saving model to next_words.h5\n",
            "458/458 [==============================] - 298s 650ms/step - loss: 4.2990\n",
            "Epoch 11/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 3.9877\n",
            "Epoch 11: loss improved from 4.29899 to 3.98766, saving model to next_words.h5\n",
            "458/458 [==============================] - 306s 669ms/step - loss: 3.9877\n",
            "Epoch 12/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 3.6533\n",
            "Epoch 12: loss improved from 3.98766 to 3.65330, saving model to next_words.h5\n",
            "458/458 [==============================] - 299s 652ms/step - loss: 3.6533\n",
            "Epoch 13/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 3.3363\n",
            "Epoch 13: loss improved from 3.65330 to 3.33630, saving model to next_words.h5\n",
            "458/458 [==============================] - 302s 660ms/step - loss: 3.3363\n",
            "Epoch 14/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 3.0169\n",
            "Epoch 14: loss improved from 3.33630 to 3.01687, saving model to next_words.h5\n",
            "458/458 [==============================] - 303s 661ms/step - loss: 3.0169\n",
            "Epoch 15/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 2.7293\n",
            "Epoch 15: loss improved from 3.01687 to 2.72928, saving model to next_words.h5\n",
            "458/458 [==============================] - 306s 669ms/step - loss: 2.7293\n",
            "Epoch 16/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 2.4716\n",
            "Epoch 16: loss improved from 2.72928 to 2.47163, saving model to next_words.h5\n",
            "458/458 [==============================] - 315s 688ms/step - loss: 2.4716\n",
            "Epoch 17/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 2.2230\n",
            "Epoch 17: loss improved from 2.47163 to 2.22299, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 645ms/step - loss: 2.2230\n",
            "Epoch 18/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 1.9992\n",
            "Epoch 18: loss improved from 2.22299 to 1.99919, saving model to next_words.h5\n",
            "458/458 [==============================] - 293s 639ms/step - loss: 1.9992\n",
            "Epoch 19/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 1.7846\n",
            "Epoch 19: loss improved from 1.99919 to 1.78459, saving model to next_words.h5\n",
            "458/458 [==============================] - 305s 665ms/step - loss: 1.7846\n",
            "Epoch 20/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 1.5767\n",
            "Epoch 20: loss improved from 1.78459 to 1.57666, saving model to next_words.h5\n",
            "458/458 [==============================] - 296s 645ms/step - loss: 1.5767\n",
            "Epoch 21/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 1.3976\n",
            "Epoch 21: loss improved from 1.57666 to 1.39757, saving model to next_words.h5\n",
            "458/458 [==============================] - 313s 684ms/step - loss: 1.3976\n",
            "Epoch 22/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 1.2289\n",
            "Epoch 22: loss improved from 1.39757 to 1.22890, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 645ms/step - loss: 1.2289\n",
            "Epoch 23/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 1.0694\n",
            "Epoch 23: loss improved from 1.22890 to 1.06942, saving model to next_words.h5\n",
            "458/458 [==============================] - 297s 648ms/step - loss: 1.0694\n",
            "Epoch 24/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.9068\n",
            "Epoch 24: loss improved from 1.06942 to 0.90681, saving model to next_words.h5\n",
            "458/458 [==============================] - 296s 646ms/step - loss: 0.9068\n",
            "Epoch 25/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.7867\n",
            "Epoch 25: loss improved from 0.90681 to 0.78671, saving model to next_words.h5\n",
            "458/458 [==============================] - 294s 641ms/step - loss: 0.7867\n",
            "Epoch 26/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.6739\n",
            "Epoch 26: loss improved from 0.78671 to 0.67394, saving model to next_words.h5\n",
            "458/458 [==============================] - 297s 648ms/step - loss: 0.6739\n",
            "Epoch 27/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.5718\n",
            "Epoch 27: loss improved from 0.67394 to 0.57182, saving model to next_words.h5\n",
            "458/458 [==============================] - 298s 651ms/step - loss: 0.5718\n",
            "Epoch 28/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.5121\n",
            "Epoch 28: loss improved from 0.57182 to 0.51211, saving model to next_words.h5\n",
            "458/458 [==============================] - 298s 651ms/step - loss: 0.5121\n",
            "Epoch 29/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.4529\n",
            "Epoch 29: loss improved from 0.51211 to 0.45290, saving model to next_words.h5\n",
            "458/458 [==============================] - 293s 639ms/step - loss: 0.4529\n",
            "Epoch 30/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.3973\n",
            "Epoch 30: loss improved from 0.45290 to 0.39732, saving model to next_words.h5\n",
            "458/458 [==============================] - 301s 658ms/step - loss: 0.3973\n",
            "Epoch 31/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.3726\n",
            "Epoch 31: loss improved from 0.39732 to 0.37263, saving model to next_words.h5\n",
            "458/458 [==============================] - 296s 645ms/step - loss: 0.3726\n",
            "Epoch 32/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.3455\n",
            "Epoch 32: loss improved from 0.37263 to 0.34546, saving model to next_words.h5\n",
            "458/458 [==============================] - 302s 659ms/step - loss: 0.3455\n",
            "Epoch 33/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.3337\n",
            "Epoch 33: loss improved from 0.34546 to 0.33367, saving model to next_words.h5\n",
            "458/458 [==============================] - 297s 648ms/step - loss: 0.3337\n",
            "Epoch 34/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.3103\n",
            "Epoch 34: loss improved from 0.33367 to 0.31034, saving model to next_words.h5\n",
            "458/458 [==============================] - 302s 659ms/step - loss: 0.3103\n",
            "Epoch 35/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.3060\n",
            "Epoch 35: loss improved from 0.31034 to 0.30600, saving model to next_words.h5\n",
            "458/458 [==============================] - 299s 652ms/step - loss: 0.3060\n",
            "Epoch 36/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2995\n",
            "Epoch 36: loss improved from 0.30600 to 0.29946, saving model to next_words.h5\n",
            "458/458 [==============================] - 297s 648ms/step - loss: 0.2995\n",
            "Epoch 37/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2753\n",
            "Epoch 37: loss improved from 0.29946 to 0.27527, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 643ms/step - loss: 0.2753\n",
            "Epoch 38/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2647\n",
            "Epoch 38: loss improved from 0.27527 to 0.26467, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 644ms/step - loss: 0.2647\n",
            "Epoch 39/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2616\n",
            "Epoch 39: loss improved from 0.26467 to 0.26163, saving model to next_words.h5\n",
            "458/458 [==============================] - 294s 642ms/step - loss: 0.2616\n",
            "Epoch 40/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2584\n",
            "Epoch 40: loss improved from 0.26163 to 0.25844, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 643ms/step - loss: 0.2584\n",
            "Epoch 41/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2570\n",
            "Epoch 41: loss improved from 0.25844 to 0.25699, saving model to next_words.h5\n",
            "458/458 [==============================] - 304s 663ms/step - loss: 0.2570\n",
            "Epoch 42/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2519\n",
            "Epoch 42: loss improved from 0.25699 to 0.25195, saving model to next_words.h5\n",
            "458/458 [==============================] - 301s 657ms/step - loss: 0.2519\n",
            "Epoch 43/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2401\n",
            "Epoch 43: loss improved from 0.25195 to 0.24015, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 645ms/step - loss: 0.2401\n",
            "Epoch 44/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2269\n",
            "Epoch 44: loss improved from 0.24015 to 0.22686, saving model to next_words.h5\n",
            "458/458 [==============================] - 304s 663ms/step - loss: 0.2269\n",
            "Epoch 45/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2201\n",
            "Epoch 45: loss improved from 0.22686 to 0.22015, saving model to next_words.h5\n",
            "458/458 [==============================] - 290s 633ms/step - loss: 0.2201\n",
            "Epoch 46/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2247\n",
            "Epoch 46: loss did not improve from 0.22015\n",
            "458/458 [==============================] - 297s 648ms/step - loss: 0.2247\n",
            "Epoch 47/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2131\n",
            "Epoch 47: loss improved from 0.22015 to 0.21308, saving model to next_words.h5\n",
            "458/458 [==============================] - 288s 629ms/step - loss: 0.2131\n",
            "Epoch 48/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2166\n",
            "Epoch 48: loss did not improve from 0.21308\n",
            "458/458 [==============================] - 293s 638ms/step - loss: 0.2166\n",
            "Epoch 49/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2117\n",
            "Epoch 49: loss improved from 0.21308 to 0.21173, saving model to next_words.h5\n",
            "458/458 [==============================] - 295s 645ms/step - loss: 0.2117\n",
            "Epoch 50/50\n",
            "458/458 [==============================] - ETA: 0s - loss: 0.2147\n",
            "Epoch 50: loss did not improve from 0.21173\n",
            "458/458 [==============================] - 318s 694ms/step - loss: 0.2147\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d0482499c90>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('next_words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "\n",
        "  print(predicted_word)\n",
        "  return predicted_word\n",
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "\n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "\n",
        "  else:\n",
        "      try:\n",
        "          # text = text.split(\" \")\n",
        "          # text = text[-3:]\n",
        "          print(text)\n",
        "\n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue"
      ],
      "metadata": {
        "id": "Lf0ED-3vpxCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhxkiHJOJIjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}